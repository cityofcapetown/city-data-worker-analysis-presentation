{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPM Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes the analysis of the HR IPM data with respect to answering questions around different types of data-related work happening at the City."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas\n",
    "import numpy\n",
    "import sklearn.decomposition\n",
    "import sklearn.metrics.pairwise\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, output_file, show, output_notebook\n",
    "from bokeh.palettes import Category20, Category20b, Category20c\n",
    "from bokeh.models import ColumnDataSource, LabelSet, Legend, BoxAnnotation, LinearAxis, Range1d, Arrow\n",
    "from bokeh.transform import dodge\n",
    "from bokeh.core.properties import value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import json\n",
    "from collections import Counter\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = json.load(open(\"./secrets/secrets.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_utils import minio_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_na_df = minio_utils.minio_to_dataframe(\n",
    "    minio_bucket=\"hr-ipm-data-non-admin\",\n",
    "    minio_key=secrets[\"minio\"][\"confidential\"][\"access\"],\n",
    "    minio_secret=secrets[\"minio\"][\"confidential\"][\"secret\"],\n",
    "    data_classification=minio_utils.DataClassification.CONFIDENTIAL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_admin_df = minio_utils.minio_to_dataframe(\n",
    "    minio_bucket=\"hr-ipm-data-admin\",\n",
    "    minio_key=secrets[\"minio\"][\"confidential\"][\"access\"],\n",
    "    minio_secret=secrets[\"minio\"][\"confidential\"][\"secret\"],\n",
    "    data_classification=minio_utils.DataClassification.CONFIDENTIAL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_strategy_affliated = minio_utils.minio_to_dataframe(\n",
    "    minio_bucket=\"data-strategy-affliated\",\n",
    "    minio_key=secrets[\"minio\"][\"confidential\"][\"access\"],\n",
    "    minio_secret=secrets[\"minio\"][\"confidential\"][\"secret\"],\n",
    "    data_classification=minio_utils.DataClassification.CONFIDENTIAL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an example df that will be used to illustrate the mapping process, using yours truly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_name = 'Gordon Inggs'\n",
    "\n",
    "example_hr_source_df = hr_na_df.query(\n",
    "    \"EmployeeName == @employee_name\"\n",
    ")[[\"Directorate\", \"Department\", \"PositionName\", \"CriteriaGroup\", \"Row\", \"AppraisalScoreWeight\"]]\n",
    "\n",
    "example_hr_source_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_hr_source_df.to_html(\n",
    "    './report/gordon_source_df.html', index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Space Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [spaCy's English large model](https://github.com/explosion/spacy-models/releases/tag/en_core_web_lg-2.1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of embarrisingly parallel operations, hence, it makes sense to define a parallel helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PROCS = 16\n",
    "N_CHUNKS = N_PROCS*4\n",
    "MIN_CHUNKSIZE = 10000\n",
    "\n",
    "def parallel_helper(data_df, df_apply, unordered=True):\n",
    "    with multiprocessing.Pool(N_PROCS) as pool:\n",
    "        chunk_size = max(data_df.shape[0] // N_CHUNKS + 1, MIN_CHUNKSIZE)\n",
    "\n",
    "        # Chunk up the dataframe\n",
    "        df_chunks = (\n",
    "            (data_df.iloc[i * chunk_size:(i + 1) * chunk_size])\n",
    "            for i in range(N_CHUNKS)\n",
    "        )\n",
    "\n",
    "        # Chunking work across processors\n",
    "        imap_func = pool.imap_unordered if unordered else pool.imap\n",
    "        result_chunks = imap_func(\n",
    "            df_apply,\n",
    "            df_chunks\n",
    "        )\n",
    "\n",
    "        # Pull it all back together\n",
    "        results = pandas.concat(result_chunks)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any sort of NLP, we need to define our domain specific stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def get_non_stop_words(data_df):\n",
    "    return data_df.Row.apply(\n",
    "        lambda x: [\n",
    "            token.text.lower() \n",
    "            for token in nlp(x) \n",
    "            if not token.is_punct and not token.is_stop\n",
    "        ]\n",
    "    )\n",
    "\n",
    "non_stop_words = parallel_helper(\n",
    "    pandas.concat([hr_admin_df, hr_na_df]),\n",
    "    get_non_stop_words,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_stop_word_counter = Counter([\n",
    "    word\n",
    "    for row in non_stop_words\n",
    "    for word in row\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_stop_word_counter.most_common()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = {\n",
    "    \"service\", \"delivery\", # All of us are doing this\n",
    "    \"function\", \"functions\", # City-dialect for job\n",
    "    \"orientation\", \"orientations\", # City-dialect for skill\n",
    "    \"problem\", \"solving\", # Again, all of us should be doing this\n",
    "    \"cfadm\", \"cfpro\", \"cfuni\", \"cfsup\", \"cfart\", \"cfman\", \"cfart\", \"cftec\", # Competency frameworks - \n",
    "    \"kpaa\", \"kpan\", # KPA classifications\n",
    "    \"l1\",  \"l2\", \"l3\", \"l4\", \"l5\" # Level descriptions - captured in T-level\n",
    "}\n",
    "nlp.Defaults.stop_words |= stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to actually map the `Row` column values into the vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def get_vectors(data_df):\n",
    "    return data_df.Row.apply(\n",
    "        lambda row: nlp(row.lower()).vector\n",
    "    )\n",
    "\n",
    "for hr_df in (hr_na_df, hr_admin_df):\n",
    "    row_vectors = parallel_helper(\n",
    "        hr_df,\n",
    "        get_vectors,\n",
    "        unordered=False,\n",
    "    )\n",
    "    hr_df[\"RowVector\"] = row_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_hr_df = hr_na_df.query(\n",
    "    \"EmployeeName == @employee_name\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_hr_df[\n",
    "    [\"Directorate\", \"Department\", \"PositionName\", \"CriteriaGroup\", \"Row\", \"RowVector\", \"AppraisalScoreWeight\"]\n",
    "].to_html(\n",
    "    './report/gordon_source_wv_df.html', index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.vstack(\n",
    "    example_hr_df[\"RowVector\"].values\n",
    ").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing from Criteria -> Poisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using centre of mass formula:\n",
    "\n",
    "$$C = \\frac{\\sum_i^N{W_i X_i}}{\\sum_i^N{W_i}}$$\n",
    "\n",
    "* $C$ - new position\n",
    "* $N$ - Number of entries in row $i$\n",
    "* $W_i$ - row $i$'s weight\n",
    "* $X_i$ - row $i$'s vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_to_cg(hr_df):\n",
    "    criteria_group_df = hr_df.groupby([\n",
    "        'Directorate', 'Department', 'EmployeeNumber', 'EmployeeName',\n",
    "        'PositionNumber', 'PositionName', 'PayScaleGroup', 'Template', \n",
    "        'CriteriaGroup', 'Criterion', 'TLevel'\n",
    "    ]).apply(\n",
    "        lambda position_cg_df: (\n",
    "            position_cg_df.AppraisalScoreWeight*position_cg_df.RowVector\n",
    "        ).sum()/(\n",
    "            position_cg_df.AppraisalScoreWeight.sum()\n",
    "        )\n",
    "    ).reset_index()\n",
    "\n",
    "    criteria_group_df[\"CriteriaGroupVector\"] = criteria_group_df[0]\n",
    "    criteria_group_df.drop(0, axis='columns', inplace=True)\n",
    "\n",
    "    return criteria_group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria_group_admin_df = reduce_to_cg(hr_admin_df)\n",
    "criteria_group_na_df = reduce_to_cg(hr_na_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criteria_group_weights(criteria, index_string):\n",
    "    criteria_set = set(criteria.values)\n",
    "    \n",
    "    if criteria_set == {'KPA', 'Competency objective'}:\n",
    "        criteria_weights_dict = {'KPA': 70, 'Competency objective': 30}\n",
    "    elif criteria_set == {'KPA', 'Competency objective', 'CMC'}:\n",
    "        criteria_weights_dict = {'KPA': 70, 'Competency objective': 20, 'CMC': 10}\n",
    "    elif criteria_set == {'CMC', 'Competency objective', 'KID objective', 'KPA'}:\n",
    "        criteria_weights_dict = {'KPA': 20, 'Competency objective': 20, 'CMC': 30, 'KID objective': 30}\n",
    "    else:\n",
    "        print(f\"Irregular criteria set: '{criteria_set}' at index '{index_string}'. Falling back to equal weighting\")\n",
    "        return numpy.array([1 for criterion in criteria])\n",
    "        #criteria_weights_dict = {'KPA': 20, 'Competency objective': 20, 'CMC': 30, 'KID objective': 30}\n",
    "        \n",
    "    criteria_weights = numpy.array([\n",
    "        criteria_weights_dict[criterion]\n",
    "        for criterion in criteria\n",
    "    ])\n",
    "    \n",
    "    return criteria_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_to_position(criteria_group_df):\n",
    "    position_df = criteria_group_df.groupby([\n",
    "        'Directorate', 'Department', 'EmployeeNumber',\n",
    "        'EmployeeName', 'PositionNumber', 'PositionName',\n",
    "        'PayScaleGroup', 'Template', 'TLevel'\n",
    "    ]).apply(\n",
    "            lambda position_df: (\n",
    "                position_df.CriteriaGroupVector*get_criteria_group_weights(position_df.Criterion, position_df.index.values[0])\n",
    "            ).sum() / (\n",
    "                get_criteria_group_weights(position_df.Criterion, \"\")\n",
    "            ).sum()\n",
    "    ).reset_index()\n",
    "\n",
    "    position_df[\"PositionVector\"] = position_df[0]\n",
    "    position_df.drop(0, axis='columns', inplace=True)\n",
    "\n",
    "    return position_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_admin_df = reduce_to_position(criteria_group_admin_df)\n",
    "position_na_df = reduce_to_position(criteria_group_na_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assembling Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_criteria_group_df = criteria_group_na_df.query(\n",
    "    \"EmployeeName == @employee_name\"\n",
    ")[[\"Directorate\", \"Department\", \"PositionName\", \"CriteriaGroup\", \"CriteriaGroupVector\"]]\n",
    "example_criteria_group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_criteria_group_df.to_html(\n",
    "    './report/gordon_cg_df.html', index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_position_df = position_na_df.query(\n",
    "    \"EmployeeName == @employee_name\"\n",
    ")[[\"Directorate\", \"Department\", \"PositionName\", \"PositionVector\"]]\n",
    "example_position_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_position_df.to_html(\n",
    "    './report/gordon_position_df.html', index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = example_hr_df.merge(\n",
    "    example_criteria_group_df[[\"CriteriaGroup\", \"CriteriaGroupVector\"]],\n",
    ").merge(\n",
    "    example_position_df[[\"PositionName\", \"PositionVector\"]]\n",
    ")[[\"Row\", \"RowVector\", \"CriteriaGroup\", \"CriteriaGroupVector\", \"PositionName\", \"PositionVector\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing Vectors for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vectors = numpy.vstack(\n",
    "    example_df.RowVector.append([\n",
    "        example_df.CriteriaGroupVector,\n",
    "        example_df.PositionVector\n",
    "    ]).drop_duplicates().values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA(n_components=2).fit(all_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df[\"RowVectorReduced\"] = example_df.RowVector.apply(\n",
    "    lambda row: pca.transform([row])\n",
    ")\n",
    "example_df[\"CriteriaGroupVectorReduced\"] = example_df.CriteriaGroupVector.apply(\n",
    "    lambda cg: pca.transform([cg])\n",
    ")\n",
    "example_df[\"PositionVectorReduced\"] = example_df.PositionVector.apply(\n",
    "    lambda pos: pca.transform([pos])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_flat_vector(pd_series):\n",
    "    return pandas.DataFrame(\n",
    "        numpy.vstack(pd_series.values)\n",
    "    ).drop_duplicates().values\n",
    "\n",
    "row_source = ColumnDataSource(data={\n",
    "    \"pca1\": produce_flat_vector(example_df.RowVectorReduced)[:,0],\n",
    "    \"pca2\": produce_flat_vector(example_df.RowVectorReduced)[:,1],\n",
    "    \"labels\": example_df.Row\n",
    "})\n",
    "cg_source = ColumnDataSource(data={\n",
    "    \"pca1\": produce_flat_vector(example_df.CriteriaGroupVectorReduced)[:,0],\n",
    "    \"pca2\": produce_flat_vector(example_df.CriteriaGroupVectorReduced)[:,1],\n",
    "    \"labels\": example_df.CriteriaGroup.drop_duplicates()\n",
    "})\n",
    "position_source = ColumnDataSource(data={\n",
    "    \"pca1\": produce_flat_vector(example_df.PositionVectorReduced)[:,0],\n",
    "    \"pca2\": produce_flat_vector(example_df.PositionVectorReduced)[:,1],\n",
    "    \"labels\": [\"Gordon\"]   \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file('./report/hr_translation_I.html')\n",
    "\n",
    "fig = figure(\n",
    "    width=600, height=600, title=\"Mapping Gordon's Criteria into his City Position\", \n",
    "    x_range=(-2.1, 4.5), background_fill_color=\"#fafafa\"\n",
    ")\n",
    "\n",
    "colour_dict = {\n",
    "    \"Criteria\": \"Blue\",\n",
    "    \"Criteria Group\": \"Red\",\n",
    "    \"Position\": \"Green\"\n",
    "}\n",
    "scatter_size_dict = {\n",
    "    \"Criteria\": 10,\n",
    "    \"Criteria Group\": 20,\n",
    "    \"Position\": 50\n",
    "}\n",
    "font_size_dict = {\n",
    "    \"Criteria\": \"10px\",\n",
    "    \"Criteria Group\": \"15px\",\n",
    "    \"Position\": \"20px\"\n",
    "}\n",
    "    \n",
    "\n",
    "def add_line(start_coord, end_coord, colour_key):\n",
    "    diff = (end_coord[0] - start_coord[0])*0.01\n",
    "    fig.add_layout(Arrow(\n",
    "        x_start=start_coord[0,0], y_start=start_coord[0,1],\n",
    "        x_end=end_coord[0,0]-diff[0], y_end=end_coord[0,1]-diff[1],\n",
    "        start=None, end=None, line_color=colour_dict[colour_key]\n",
    "    ))\n",
    "\n",
    "# Row -> CG Arrows\n",
    "example_df.groupby([\"CriteriaGroup\"], as_index=False).apply(\n",
    "    lambda sub_df: sub_df.RowVectorReduced.apply(\n",
    "        add_line,\n",
    "        end_coord=sub_df.CriteriaGroupVectorReduced.values[0],\n",
    "        colour_key=\"Criteria\"\n",
    "    )\n",
    ")\n",
    "# CG -> Position Arrows\n",
    "example_df.groupby([\"PositionName\"], as_index=False).apply(\n",
    "    lambda sub_df: sub_df.CriteriaGroupVectorReduced.apply(\n",
    "        add_line,\n",
    "        end_coord=sub_df.PositionVectorReduced.values[0],\n",
    "        colour_key=\"Criteria Group\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Scatters\n",
    "for (name, source) in zip([\"Criteria\", \"Criteria Group\", \"Position\"], \n",
    "                          [row_source, cg_source, position_source]):\n",
    "    fig.scatter(\n",
    "        x=\"pca1\", y=\"pca2\", source=source, \n",
    "        size=scatter_size_dict[name], color=colour_dict[name], legend=name,\n",
    "    )\n",
    "    labels = LabelSet(\n",
    "        x=\"pca1\", y=\"pca2\", text=\"labels\", source=source, \n",
    "        x_offset=scatter_size_dict[name]/1.5, \n",
    "        y_offset=-scatter_size_dict[name]/1.5, \n",
    "        text_font_size=font_size_dict[name]\n",
    "    )\n",
    "    fig.add_layout(labels)\n",
    "\n",
    "fig.xaxis.visible = False\n",
    "fig.yaxis.visible = False\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example plot II - Plot Harder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_plot_na_df = position_na_df.copy().sample(5000)\n",
    "position_plot_admin_df = position_admin_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA(n_components=2).fit(\n",
    "    numpy.vstack(\n",
    "        pandas.concat((position_plot_na_df.PositionVector, position_plot_admin_df.PositionVector)).values\n",
    "    )\n",
    ")\n",
    "\n",
    "for position_plot_df in (position_plot_na_df, position_plot_admin_df):\n",
    "    position_plot_df[\"PositionVectorReduced\"] = [\n",
    "        vector \n",
    "        for vector in pca.transform(\n",
    "            numpy.vstack(position_plot_df.PositionVector.values)\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position_source_dict(position_plot_df):\n",
    "    directorates = position_plot_na_df.Directorate.unique()\n",
    "    \n",
    "    all_position_source = {\n",
    "        directorate: ColumnDataSource(data={\n",
    "            \"pca1\": numpy.vstack(position_plot_df.query(\"Directorate==@directorate\").PositionVectorReduced.values)[:,0],\n",
    "            \"pca2\": numpy.vstack(position_plot_df.query(\"Directorate==@directorate\").PositionVectorReduced.values)[:,1],\n",
    "            \"directorate\": position_plot_df.query(\"Directorate==@directorate\").Directorate.str.title(),\n",
    "            \"department\": position_plot_df.query(\"Directorate==@directorate\").Department.str.title(),\n",
    "            \"position\": position_plot_df.query(\"Directorate==@directorate\").PositionName,\n",
    "        }) for directorate in directorates\n",
    "    }\n",
    "    \n",
    "    return all_position_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_position_plot(position_plot_df, output_path, plot_title):\n",
    "    all_position_source = get_position_source_dict(position_plot_df)\n",
    "    directorates = sorted(position_plot_na_df.Directorate.unique())\n",
    "    \n",
    "    output_file(output_path)\n",
    "\n",
    "    fig = figure(\n",
    "        width=600, height=600, title=plot_title,\n",
    "        tooltips=[\n",
    "            (\"Department\", \"@department\"),\n",
    "            (\"Position\", \"@position\"),\n",
    "        ],\n",
    "        background_fill_color=\"#fafafa\"\n",
    "    )\n",
    "\n",
    "    for i,directorate in enumerate(directorates):\n",
    "        plt = fig.scatter(\n",
    "                x=\"pca1\", y=\"pca2\", source=all_position_source[directorate], \n",
    "                size=5, color=Category20c[len(directorates)][i], alpha=0.8, muted_alpha=0.1,\n",
    "                legend=\"\".join(map(lambda x: x[0], directorate.title().split()))\n",
    "        )\n",
    "\n",
    "    fig.legend.location = \"bottom_right\"\n",
    "    fig.legend.click_policy = \"hide\"\n",
    "    fig.legend.visible = True\n",
    "\n",
    "    fig.xaxis.visible = False\n",
    "    fig.yaxis.visible = False\n",
    "\n",
    "    show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_position_plot(position_plot_na_df, './report/hr_translation_II_na.html', \"Mapping Non-Admin Positions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_position_plot(position_plot_admin_df, './report/hr_translation_II_admin.html', \"Mapping Admin Positions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA().fit(\n",
    "    numpy.vstack(\n",
    "        pandas.concat((position_plot_na_df.PositionVector, position_plot_admin_df.PositionVector)).values\n",
    "    )\n",
    ")\n",
    "\n",
    "for position_plot_df in (position_plot_na_df, position_plot_admin_df):\n",
    "    position_plot_df[\"PositionVectorReduced\"] = [\n",
    "        vector \n",
    "        for vector in pca.transform(\n",
    "            numpy.vstack(position_plot_df.PositionVector.values)\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_[:30].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Word Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = [\n",
    "    \"data\",\n",
    "    \"gathering\",\n",
    "#     \"collection\",\n",
    "#     \"acquisition\",\n",
    "#     \"accumulation\",\n",
    "    \"processing\",\n",
    "#     \"transformation\",\n",
    "    \"analysis\",\n",
    "#     \"research\",\n",
    "#     \"interpretation\",\n",
    "#     \"understanding\",\n",
    "    \"dissemination\",\n",
    "#     \"formal communication\"\n",
    "#     \"communication\",\n",
    "#     \"distribution\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_word_vectors = {\n",
    "    word: nlp(word.lower()).vector\n",
    "    for word in data_words\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_na_df = position_na_df.copy()\n",
    "score_admin_df = position_admin_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score_df in (score_na_df, score_admin_df):\n",
    "    for word, word_vector in data_word_vectors.items():\n",
    "        score_df[f\"{word.title()}Score\"] = sklearn.metrics.pairwise.cosine_similarity(\n",
    "            numpy.vstack(score_df.PositionVector.values),\n",
    "            numpy.array([word_vector])\n",
    "        )\n",
    "        #score_df[f\"{word.title()}Score\"] = numpy.linalg.norm(\n",
    "        #    (numpy.vstack(score_df.PositionVector.values) - numpy.array([word_vector])), \n",
    "        #    axis=1\n",
    "        #)\n",
    "        #score_df[f\"{word.title()}Score\"] = score_df[f\"{word.title()}Score\"]/score_df[f\"{word.title()}Score\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_score_example_df = score_na_df.query(\n",
    "    \"EmployeeName == @employee_name\"\n",
    ")[[\"Directorate\", \"Department\", \"PositionName\"] + [f\"{word.title()}Score\" for word in data_words]]\n",
    "data_score_example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_score_example_df.to_html(\n",
    "    \"./report/data_score_df.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_score_source(score_df):\n",
    "    data_score_sources = {\n",
    "        word: ColumnDataSource(data={\n",
    "            \"count\": range(score_df.shape[0]),\n",
    "            \"score\": score_df.sort_values(by=f\"{word.title()}Score\", ascending=False)[f\"{word.title()}Score\"],\n",
    "            \"directorate\": score_df.sort_values(by=f\"{word.title()}Score\", ascending=False).Directorate.str.title(),\n",
    "            \"department\": score_df.sort_values(by=f\"{word.title()}Score\", ascending=False).Department.str.title(),\n",
    "            \"position\": score_df.sort_values(by=f\"{word.title()}Score\", ascending=False).PositionName,\n",
    "        })\n",
    "        for word in data_words\n",
    "    }\n",
    "    \n",
    "    return data_score_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_word_colour_dict = {\n",
    "    \"data\": \"blue\",\n",
    "    \"gathering\": \"orange\",\n",
    "    \"processing\": \"green\",\n",
    "    \"analysis\": \"red\",\n",
    "    \"dissemination\": \"purple\",\n",
    "    #\"formal communication\": \"purple\",\n",
    "}\n",
    "# data_word_colour_dict = {\n",
    "#     word: Category20[len(data_words)][i]\n",
    "#     for i,word in enumerate(data_words)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_score_plot(score_df, output_path, plot_title, green_stop, red_start):\n",
    "    data_score_sources = generate_score_source(score_df)\n",
    "    output_file(output_path)\n",
    "\n",
    "    fig = figure(\n",
    "        width=600, height=600, title=plot_title,\n",
    "        tooltips=[\n",
    "            (\"Directorate\", \"@directorate\"),\n",
    "            (\"Department\", \"@department\"),\n",
    "            (\"Position\", \"@position\"),\n",
    "        ],\n",
    "        #x_range=(-10, 17000), #y_range=(-1.5, 2)\n",
    "        background_fill_color=\"#fafafa\"\n",
    "    )\n",
    "\n",
    "    # lines\n",
    "    for word in data_words:\n",
    "        fig.line(\n",
    "            x=\"count\", y=\"score\", source=data_score_sources[word],\n",
    "            legend=word.title(), line_color=data_word_colour_dict[word],  line_width=2\n",
    "        )\n",
    "\n",
    "    # high intensity band\n",
    "    high_threshold = green_stop\n",
    "    fig.add_layout(BoxAnnotation(\n",
    "        left=0, right=high_threshold,\n",
    "        fill_alpha=0.2, fill_color='green'\n",
    "    ))\n",
    "\n",
    "    # middle intensity band\n",
    "    low_threshold = red_start\n",
    "    fig.add_layout(BoxAnnotation(\n",
    "        left=high_threshold, right=low_threshold,\n",
    "        fill_alpha=0.2, fill_color='grey'\n",
    "    ))\n",
    "\n",
    "    # low intensity band\n",
    "    fig.add_layout(BoxAnnotation(\n",
    "        left=low_threshold, \n",
    "        fill_alpha=0.2, fill_color='red'\n",
    "    ))\n",
    "\n",
    "    fig.legend.location = \"bottom_center\"\n",
    "    fig.legend.click_policy = \"hide\"\n",
    "    fig.legend.visible = True\n",
    "\n",
    "    fig.xaxis.axis_label = 'Cumulative number of employees'\n",
    "    fig.yaxis.axis_label = 'Word Similarity'\n",
    "\n",
    "    show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_score_plot(score_na_df, './report/na_data_scoring.html', \"Distribution of Non-Administrative Data Word Scoring\", 500, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_score_plot(score_admin_df, './report/admin_data_scoring.html', \"Distribution of Administrative Data Word Scoring\", 100, 4900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characterising City Employee Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_score_df = score_na_df.sort_values(by=\"DataScore\", ascending=False).head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorate_counts = data_score_df.groupby(['Directorate']).EmployeeNumber.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "department_counts = data_score_df.groupby(['Department']).EmployeeNumber.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlevel_counts = data_score_df.groupby(['TLevel']).EmployeeNumber.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_counts = data_score_df.groupby(['PositionName']).EmployeeNumber.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file(\"report/hr_top_data_summary.html\", mode=\"cdn\")\n",
    "\n",
    "TOOLS = [\"save\"]\n",
    "\n",
    "# Directorate Plot\n",
    "directorate_figure = figure(width=400, plot_height=600, title=\"Directorate Breakdown\", x_range=directorate_counts.index.values, tools=TOOLS)\n",
    "directorate_figure.vbar(\n",
    "    directorate_counts.index.values, top=directorate_counts.values, \n",
    "    width=0.9, color=Category20[len(directorate_counts.values)]\n",
    ")\n",
    "directorate_figure.xaxis.major_label_orientation = \"vertical\"\n",
    "directorate_figure.xaxis.axis_label = \"Directorate\"\n",
    "\n",
    "# Department Plot\n",
    "depts = 15\n",
    "department_figure = figure(width=400, plot_height=600, title=f\"Department Breakdown (top {depts})\", tools=TOOLS, \n",
    "                           x_range=department_counts.index.values[:depts])\n",
    "department_figure.vbar(\n",
    "    department_counts.index.values[:depts], top=department_counts.values[:depts], \n",
    "    width=0.9, color=Category20[depts]\n",
    ")\n",
    "department_figure.xaxis.major_label_orientation = \"vertical\"\n",
    "department_figure.xaxis.axis_label = \"Department\"\n",
    "\n",
    "# T-Level Plot\n",
    "tlevel_figure = figure(width=400, plot_height=600, title=f\"T-Level Breakdown\", x_range=list(map(str,tlevel_counts.index.values[:])), tools=TOOLS)\n",
    "tlevel_figure.vbar(\n",
    "    list(map(str,tlevel_counts.index.values[:])), top=tlevel_counts.values[:], \n",
    "    width=0.9, color=Category20[len(tlevel_counts)]\n",
    ")\n",
    "tlevel_figure.xaxis.major_label_orientation = \"vertical\"\n",
    "tlevel_figure.xaxis.axis_label = \"T-Level\"\n",
    "\n",
    "# Position Plot\n",
    "positions = 15\n",
    "positions_figure = figure(\n",
    "    width=400, plot_height=600, \n",
    "    title=f\"Position Breakdown (top {positions})\", \n",
    "    x_range=position_counts.index.values[:positions], \n",
    "    tools=TOOLS,\n",
    ")\n",
    "\n",
    "positions_figure.vbar(\n",
    "    position_counts.index.values[:positions], top=position_counts.values[:positions], \n",
    "    width=0.9, color=Category20[depts]\n",
    ")\n",
    "positions_figure.xaxis.major_label_orientation = \"vertical\"\n",
    "positions_figure.xaxis.axis_label = \"Position Names\"\n",
    "\n",
    "# show the results\n",
    "show(\n",
    "    gridplot([\n",
    "        [tlevel_figure, positions_figure],\n",
    "        [directorate_figure, department_figure],\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_na_df[\"DataStrategyAffliliated\"] = score_na_df.EmployeeName.str.lower().isin(\n",
    "    data_strategy_affliated.Name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_na_df.sort_values(by=\"DataScore\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_score_comparison_source = ColumnDataSource({\n",
    "    \"data_words\": list(map(lambda x: x.title(), data_words)),\n",
    "    \"not_affliated\": [\n",
    "        score_na_df[~score_na_df.DataStrategyAffliliated][f\"{word.title()}Score\"].median()\n",
    "        for word in data_words\n",
    "    ],\n",
    "    \"affliated\": [\n",
    "        score_na_df[score_na_df.DataStrategyAffliliated][f\"{word.title()}Score\"].median()\n",
    "        for word in data_words     \n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file('./report/data_scoring_comparison_test.html')\n",
    "\n",
    "fig = figure(\n",
    "    x_range=list(map(lambda x: x.title(), data_words)),\n",
    "    y_range=(0, 0.6),\n",
    "    width=800, height=600, title=\"Median Data Word Score by Data Strategy Affliation\",\n",
    "    background_fill_color=\"#fafafa\"\n",
    ")\n",
    "\n",
    "fig.vbar(\n",
    "    x=dodge(\"data_words\", -0.1, range=fig.x_range), top='affliated', source=data_score_comparison_source,\n",
    "    width=0.2, color='blue', legend=value(\"Affliated\",)\n",
    ")\n",
    "\n",
    "fig.vbar(\n",
    "    x=dodge(\"data_words\", 0.1, range=fig.x_range), top='not_affliated', source=data_score_comparison_source,\n",
    "    width=0.2, color='grey', legend=value(\"Not Affliated\",)\n",
    ")\n",
    "\n",
    "fig.yaxis.axis_label = 'Median Data Word Score'\n",
    "fig.xaxis.axis_label = 'Data Word'\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_na_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA(n_components=2).fit(\n",
    "    score_na_df[[\n",
    "        f\"{word.title()}Score\"\n",
    "        for word in data_words\n",
    "    ]].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_score_vector_reduced = pca.transform(\n",
    "    score_na_df[[\n",
    "        f\"{word.title()}Score\"\n",
    "        for word in data_words\n",
    "    ]].values\n",
    ")\n",
    "score_na_df[\"PCA1\"] = data_score_vector_reduced[:,0]\n",
    "score_na_df[\"PCA2\"] = data_score_vector_reduced[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ds_sample = score_na_df[~score_na_df.DataStrategyAffliliated].sample(2000)\n",
    "ds_sample = score_na_df[score_na_df.DataStrategyAffliliated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_source = ColumnDataSource({\n",
    "    \"pca1\": non_ds_sample.PCA1,\n",
    "    \"pca2\": non_ds_sample.PCA2,\n",
    "    \"directorate\": non_ds_sample.Directorate,\n",
    "    \"department\": non_ds_sample.Department,\n",
    "    \"position\": non_ds_sample.PositionName,\n",
    "})\n",
    "pca_source_ds = ColumnDataSource({\n",
    "    \"pca1\": ds_sample.PCA1,\n",
    "    \"pca2\": ds_sample.PCA2,\n",
    "    \"directorate\": ds_sample.Directorate,\n",
    "    \"department\": ds_sample.Department,\n",
    "    \"position\": ds_sample.PositionName,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_loadings = pca.components_.T * numpy.sqrt(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file('./report/data_scoring_pca_test.html')\n",
    "\n",
    "fig = figure(\n",
    "    width=600, height=600, title=\"Data Scoring Component Analysis\",\n",
    "    tooltips=[\n",
    "        (\"Directorate\", \"@directorate\"),\n",
    "        (\"Department\", \"@department\"),\n",
    "        (\"Position\", \"@position\"),\n",
    "    ],\n",
    "    x_range=(-0.6, 0.6), y_range=(-0.5, 0.5),\n",
    "    x_axis_label=\"PCA Dimenions 1\", y_axis_label=\"PCA Dimension 2\",\n",
    "    background_fill_color=\"#fafafa\"\n",
    ")\n",
    "fig.extra_y_ranges = {\"vector_y_axis\": Range1d(start=-0.05, end=0.05)}\n",
    "fig.extra_x_ranges = {\"vector_x_axis\": Range1d(start=-0.06, end=0.06)}\n",
    "\n",
    "fig.add_layout(LinearAxis(y_range_name=\"vector_y_axis\", axis_label='Component Dimension 1'), \n",
    "               'right')\n",
    "fig.add_layout(LinearAxis(x_range_name=\"vector_x_axis\", axis_label='Component Dimension 1'), \n",
    "               'above')\n",
    "\n",
    "#City Positions\n",
    "fig.scatter(\n",
    "    x=\"pca1\", y=\"pca2\", source=pca_source, \n",
    "    size=5, color='grey', alpha=0.8,\n",
    "    legend=\"Not DS Affliated\"\n",
    ")\n",
    "fig.scatter(\n",
    "    x=\"pca1\", y=\"pca2\", source=pca_source_ds, \n",
    "    size=5, color='blue', alpha=0.8,\n",
    "    legend=\"DS Affliated\"\n",
    ")\n",
    "\n",
    "for word, vector_position in zip(data_words, vector_loadings):\n",
    "    fig.line(\n",
    "        x=(0, vector_position[0]), y=(0, vector_position[1]),\n",
    "        x_range_name=\"vector_x_axis\", y_range_name=\"vector_y_axis\",\n",
    "        line_width=2, color=data_word_colour_dict[word], legend=word.title()\n",
    "    )\n",
    "\n",
    "fig.legend.location = \"top_right\"\n",
    "fig.legend.click_policy = \"hide\"\n",
    "fig.legend.visible = True\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
